# PyTorch Learning Lab

This repository contains a collection of notebooks documenting my progression learning PyTorch and deep learning from first principles

The focus is on understanding how models are build using tensor operations and training loops, as well as CNNs and evaluation

## Purpose

This repository exists to:
- Build intuition for deep learning fundamentals
- Practice implementing models directly in PyTorch
- Experimenting with architecture and hyperparameter choices to see affects on performance
- Hands-on experimentation

## Tools & Technologies

- Python
- PyTorch
- Neural Networks
- NumPy
- Pandas
- Matplotlib
- scikit-learn
- Jupyter Notebooks
- Google Colab (for prototyping and experimentation)

## What Youâ€™ll Find Here

Examples of topics covered include:
- Tensor operations and automatic differentiation
- Custom training and evaluation loops
- Loss functions and optimization techniques
- Feedforward neural networks
- Convolutional neural networks (CNNs)
- Dataset loading and preprocessing
- Model evaluation and performance metrics

## Notes

These notebooks reflect an **iterative learning process**.  
Code style and structure vary intentionally to support experimentation and conceptual clarity.

Over time, concepts explored here are refined and applied in larger, fully scoped ML projects.
