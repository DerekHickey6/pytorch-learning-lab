{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerekHickey6/pytorch-learning-lab/blob/main/05_pytorch_computervision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "This notebook builds a basic computer vision pipeline using PyTorch, including\n",
        "dataset handling, CNN architecture design, training, and evaluation. The focus\n",
        "is on applying deep learning techniques to image-based tasks.\n"
      ],
      "metadata": {
        "id": "M68O76Se4MTp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo4LI7Q817-S"
      },
      "source": [
        "## PyTorch Computer Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDWkkKYh9kk5"
      },
      "source": [
        "### 0. Computer Vision libraries in PyTorch\n",
        "\n",
        "* `torchvision` - base library for computer vision\n",
        "* `torchvision.datasets` - gets datasets and data loading functions\n",
        "* `torchvision.models` - get pretrained computer vision models the you can leverage for your own problems\n",
        "* `torchvision.transforms` - functions for manipulating your vision data, to be suitable for use with ML model\n",
        "* `torch.utils.data.dataset` - base dataset class for PyTorch\n",
        "* `torch.utils.data.dataloader` - creates a python iterable over a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv-P1rbkAyeD"
      },
      "outputs": [],
      "source": [
        "# import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJyAgL3e9kg7"
      },
      "source": [
        "## 1. Getting a dataset\n",
        "\n",
        "the dataset we'll be using is FashionMNIST database from torchvision.datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuW6elL6AyeE"
      },
      "outputs": [],
      "source": [
        "# Setup Training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download to\n",
        "    train=True, # do we want the training data set?\n",
        "    download=True, # do we want to download?\n",
        "    transform=torchvision.transforms.ToTensor(), # how do we want to transform the data?\n",
        "    target_transform=None # how do we want to transform the labels/targets\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download to\n",
        "    train=False, # do we want the training data set?\n",
        "    download=True, # do we want to download?\n",
        "    transform=ToTensor(), # how do we want to transform the data?\n",
        "    target_transform=None # how do we want to transform the labels/targets\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc9AqiCAAyeF"
      },
      "outputs": [],
      "source": [
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNk6iMMSAyeF"
      },
      "outputs": [],
      "source": [
        "# See the first training examples\n",
        "image, label = train_data[0]\n",
        "image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmL-4wwpAyeF"
      },
      "outputs": [],
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecKRRo0dAyeF"
      },
      "outputs": [],
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e84X1rdIAyeF"
      },
      "outputs": [],
      "source": [
        "train_data.targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90hGS_uLKWKJ"
      },
      "source": [
        "## 1.1 Check the input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OilTKgbHAyeF"
      },
      "outputs": [],
      "source": [
        "# Check the shape\n",
        "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\") ## only 1 color channel, because pictures are black and white\n",
        "print(f\"label: {class_names[label]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYrfSsMZFbJd"
      },
      "source": [
        "## 1.2 Visualize our images/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug5T9DNDAyeF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ-4XtZcAyeG"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvYEKtR1AyeG"
      },
      "outputs": [],
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqe5KtrsFbBH"
      },
      "source": [
        "## 2. Prepare Dataloader\n",
        "\n",
        "data is currently in the form of pytorch datasets\n",
        "\n",
        "Dataloader turns our dataset into a python iterable - we want to turn our data into mini-batches\n",
        "\n",
        "1. more computationally effiecient - computer hardware may not be able to look at 60000 images in 1 hit.\n",
        "2. It gives out neural network more chances to update its gradients per epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAZuFvLDAyeG"
      },
      "outputs": [],
      "source": [
        "train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sUkY5LKAyeG"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size Hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# turn data into dataloader iterables (batches)\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVsYIpHkAyeG"
      },
      "outputs": [],
      "source": [
        "# Lets checkout what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train_dataloader: {len(train_dataloader)}, batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test_dataloader: {len(test_dataloader)}, batches of {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvIdwn7HAyeG"
      },
      "outputs": [],
      "source": [
        "# check out whats inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHrOkTmQAyeG"
      },
      "outputs": [],
      "source": [
        "# show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl4YjWJjKaT6"
      },
      "source": [
        "## 3. Model_0: Build a baseline model\n",
        "\n",
        "Whens starting to build a series of machine learning modelling experiments, its important to start with a baseline model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XT-rUglAyeG"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "# Create a flatten layer\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_model(x) ## perform the forward pass\n",
        "\n",
        "# Print out what happened\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape}     -> [color_channels, height*width]\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbIOwzJTAyeG"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugUMO74SAyeG"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Setup model with input parameters\n",
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape=784,   # this is 28*28\n",
        "    hidden_units=10,   ### how many units in the hidden layer\n",
        "    output_shape=len(class_names)    ## 1 for every class\n",
        ").to(\"cpu\")\n",
        "\n",
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJCjp4heAyeG"
      },
      "outputs": [],
      "source": [
        "dummy_x = torch.rand([1, 1, 28, 28])\n",
        "model_0(dummy_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwuz72MWc5Yg"
      },
      "source": [
        "### 3.1 Setup loss, optimizer and evaluation metrics\n",
        "\n",
        "* loss function - with multiclass data, out loss will be `nn.CrossEntropyLoss`\n",
        "* optimizer - out optimizer will be `toch.optim.SGD` for gradient descent\n",
        "* Evauluation metric - since were working on a classification problem, lets use accuray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMXEpciBAyeG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from learnPyTorch repo\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download...\")\n",
        "else:\n",
        "  print(\"downloading helper_function.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW8nVb2yAyeG"
      },
      "outputs": [],
      "source": [
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr= 0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nChU4G7hJByp"
      },
      "source": [
        "### 3.2 Creating a function to time out experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jujuoTDHAyeH"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  \"\"\" Prints difference between start and end time\"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwcKD5cQAyeH"
      },
      "outputs": [],
      "source": [
        "start_time = timer()\n",
        "## some code\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=\"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpWpmebMKfmr"
      },
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data\n",
        "\n",
        "* IMPORTANT: the optimizer will update a model's parameters after each batch instead of each epoch\n",
        "\n",
        "1. Loop through epochs\n",
        "2. Loop through training batches, perform training steps, calculate train loss *per batch*\n",
        "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*\n",
        "4. Print out whats happening\n",
        "5. Time it all (for fun)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLh7IHhUAyeH"
      },
      "outputs": [],
      "source": [
        "train_dataloader.dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkzxAz6OVA17"
      },
      "source": [
        "## Model for recognizing clothing from database of 60000 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdv5EbNGAyeH"
      },
      "outputs": [],
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Setup the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Set the number of epochs ( keep small for faster training time )\n",
        "epochs = 3\n",
        "\n",
        "# Create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  ### training\n",
        "  train_loss = 0\n",
        "  # Add a loop to loop through the training batches\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    # 2. Calculate the loss ( per batch)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss # accumulate the training loss values every batch\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer Step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out whats happening\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)}\")\n",
        "  # divide total_train loss by length of train dataloader for average loss per epoch\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  ### Testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      # 1. forward pass\n",
        "      test_pred = model_0(X_test)\n",
        "\n",
        "      # 2. Calculate the loss accumulatively\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # calculate the test accuracy average per batch\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  # Print out whats happening\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
        "\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                            end=train_time_end_on_cpu,\n",
        "                                            device=str(next(model_0.parameters()).device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTFpKqsxLhC2"
      },
      "source": [
        "# 4. Make predictions and get model_0 results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvDOG89rAyeH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "  \"\"\"Returns a dictionary containing the results of model predicitons on data_loader\"\"\"\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      # Make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Accumulate the loss and acc values per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y,\n",
        "                         y_pred=y_pred.argmax(dim=1))\n",
        "    # scale the loss and acc to find the avg loss/acc per batch\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__,  ## only works when model was created with a different class\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}\n",
        "\n",
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn)\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiXLGao2AyeH"
      },
      "outputs": [],
      "source": [
        "## 5. Setup device agnostic code for using a GPU if available\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW-WIpA0a6kB"
      },
      "source": [
        "## 6. Model 1: Building a better model with non-linearity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9_L7womAyeH"
      },
      "outputs": [],
      "source": [
        "# Create a model with non-layer and linear layers\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(), ## flattens input into a single vector\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.layer_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGGti97VAyeH"
      },
      "outputs": [],
      "source": [
        "# Create an instance of model_1\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = FashionMNISTModelV1(input_shape=784,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device) # sends to gpu if available\n",
        "\n",
        "next(model_1.parameters()).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFnBE-aDAyeI"
      },
      "outputs": [],
      "source": [
        "from helper_functions import accuracy_fn\n",
        "# Create loss function and optimizer for model_1\n",
        "loss_fn = nn.CrossEntropyLoss()  ## measure how wrong the model is\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),   # tries to update our models parameters to redue the loss\n",
        "                            lr=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtHNhe0k3cCW"
      },
      "source": [
        "### 6.2 Functionizing training and evaluation/testing loops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1W2Im5NAyeI"
      },
      "outputs": [],
      "source": [
        "# Functionizing Training loop\n",
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  \"\"\" Performs a traing with model trying to learn on data_loader\"\"\"\n",
        "  ### training\n",
        "\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  model.train()\n",
        "  # Add a loop to loop through the training batches\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    # Put data on target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # 2. Calculate the loss and accuracy ( per batch)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss # accumulate the training loss values every batch\n",
        "    train_acc += accuracy_fn(y_true=y,\n",
        "                             y_pred=y_pred.argmax(dim=1)) # go from logits to -> prediction labels\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer Step\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  # divide total_train loss and accuarcy by length of train dataloader for average loss per epoch\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs1WhsDbAyeI"
      },
      "outputs": [],
      "source": [
        "# Functionize the testing loop\n",
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  \"\"\"Performs a testing loop step going over a data_loader\"\"\"\n",
        "\n",
        "   ### Testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in data_loader:\n",
        "      # Setup device agnostic code\n",
        "      X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "      # 1. forward pass\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      # 2. Calculate the loss accumulatively\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y_test,\n",
        "                              y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(data_loader)\n",
        "\n",
        "    # calculate the test accuracy average per batch\n",
        "    test_acc /= len(data_loader)\n",
        "\n",
        "  # Print out whats happening\n",
        "  print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUlJSkxXAyeI"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "# measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_Start_on_gpu = timer()\n",
        "\n",
        "# Set epochs\n",
        "epochs = 1\n",
        "\n",
        "# Create an optimization and evaluation using train_step and test_step\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-----------\")\n",
        "  # Training\n",
        "  train_step(model=model_1,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device\n",
        "             )\n",
        "  # Testing\n",
        "  test_step(model=model_1,\n",
        "            data_loader=train_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device)\n",
        "\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                            end=train_time_end_on_cpu,\n",
        "                                            device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sclXI-sOAyeI"
      },
      "outputs": [],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML6X7c0_AyeI"
      },
      "outputs": [],
      "source": [
        "total_train_time_model_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWZGkUV5XXBg"
      },
      "source": [
        "Note ** sometimes depending on your data / hardware, the model might train faster on CPU than GPU>\n",
        "\n",
        "1. could be that the overhead for copying data / model to and from the GPU outweighs the compute benefits offered by the GPU\n",
        "\n",
        "2. the hardware your using has a better CPU in terms of compute capability than GPU ( more rare )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Resj9xFtAyeI"
      },
      "outputs": [],
      "source": [
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device=device):\n",
        "  \"\"\"Returns a dictionary containing the results of model predicitons on data_loader\"\"\"\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      # make our data device agnostic\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # Make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Accumulate the loss and acc values per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y,\n",
        "                         y_pred=y_pred.argmax(dim=1))\n",
        "    # scale the loss and acc to find the avg loss/acc per batch\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__,  ## only works when model was created with a different class\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJBuoCjrAyeI"
      },
      "outputs": [],
      "source": [
        "# Get model 1 results dictionary\n",
        "model_1_results = eval_model(model=model_1,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             device=device)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKuwwnldAyeI"
      },
      "outputs": [],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRb7LMLV85yh"
      },
      "source": [
        "## Model 2: Building a convolutional neural network\n",
        "\n",
        "CNN's are also known as ConvNets\n",
        "\n",
        "CNN's are known for their capabilities for finding patterns in visual data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTuw7ODxAyeJ"
      },
      "outputs": [],
      "source": [
        "# Create a convolutional neural network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture that replicates the TinyVGG\n",
        "  modle from CNN explainer website.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        # Create a conv layer\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naWff2jzAyeJ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt8eQz2-AyeJ"
      },
      "outputs": [],
      "source": [
        "rand_image_tensor = torch.randn(size=(1, 28, 28))\n",
        "rand_image_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClihsaXgAyeJ"
      },
      "outputs": [],
      "source": [
        "# Pass image through model\n",
        "model_2(rand_image_tensor.unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4h42788AyeJ"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ5NIIczZ4a5"
      },
      "source": [
        "### 7.1 Stepping through `nn.Conv2d()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCJ89H0UAyeJ"
      },
      "outputs": [],
      "source": [
        "# Creating dummy data\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a batch of images\n",
        "images = torch.randn(size=(32, 3, 64, 64))\n",
        "test_image = images[0]\n",
        "\n",
        "print(f\"Image batch shape: {images.shape}\")\n",
        "print(f\"Single image shape: {test_image.shape}\")\n",
        "print(f\"Test image:\\n {test_image}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siiNGdU3AyeJ"
      },
      "outputs": [],
      "source": [
        "test_image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XyPydPRAyeJ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "# Create a single conv2d layer\n",
        "conv_layer = nn.Conv2d(in_channels=3,\n",
        "                       out_channels=10,\n",
        "                       kernel_size=3, # also known as a 'filter'\n",
        "                       stride=1,  # stride of the convolving kernel\n",
        "                       padding=0)   # adds pixels around the edge, so that our kernal can operate on edges of image\n",
        "\n",
        "# pass the data through the convolutional layer\n",
        "conv_output = conv_layer(test_image)\n",
        "conv_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGjka-8per2U"
      },
      "source": [
        "## 7.3 Setup a loss function and optimizer for model_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Og4Vx1AyeJ"
      },
      "outputs": [],
      "source": [
        "# Setup loss function/eval metrics/optimizer\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
        "                            lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjcVBk93erx2"
      },
      "source": [
        "### 7.4 training and testing out model_2 using our training and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMoSzDAqAyeJ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Measure time\n",
        "from timeit import default_timer as Timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "# Train and test\n",
        "epochs = 5\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch} \\n-------\")\n",
        "  train_step(model=model_2,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "\n",
        "  test_step(model=model_2,\n",
        "            data_loader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            accuracy_fn=accuracy_fn,\n",
        "            device=device)\n",
        "\n",
        "train_time_end_model_2 = timer()\n",
        "\n",
        "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
        "                                            end=train_time_end_model_2,\n",
        "                                            device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxpEw8PDAyeJ"
      },
      "outputs": [],
      "source": [
        "# Get a results dictionary\n",
        "model_2_results = eval_model(model=model_2,\n",
        "                             data_loader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDxSS9e9AyeJ"
      },
      "outputs": [],
      "source": [
        "model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJCUBdqgAyeJ"
      },
      "outputs": [],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_dpmylWy4I1"
      },
      "source": [
        "## 8. Comparing model results and training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMDhj848AyeJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results,\n",
        "                                model_1_results,\n",
        "                                model_2_results])\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhJZ-WbCAyeK"
      },
      "outputs": [],
      "source": [
        "# Add training time to results comparison\n",
        "compare_results[\"training_time\"] = [total_train_time_model_0,\n",
        "                                    total_train_time_model_1,\n",
        "                                    total_train_time_model_2]\n",
        "compare_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h89biJYDAyeK"
      },
      "outputs": [],
      "source": [
        "# Visualize our model results\n",
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"Accuracy (%)\")\n",
        "plt.ylabel(\"model\");"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Make and evaluate random predictions with best model"
      ],
      "metadata": {
        "id": "WH76THI-AyeK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF_DSLEGAyeK"
      },
      "outputs": [],
      "source": [
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # Prepare the sample (add a batch dimension and put on target device)\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "\n",
        "      # Forward pass ( model outputs raw logits )\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      # get prediction probability ( logit -> pred prob )\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "\n",
        "      # Get pred_prob off the GPU for further calculations\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  # Stack the pred_probs to turn list into a tensor\n",
        "  return torch.stack(pred_probs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "uDhDVwkOKcyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzgPWfpvAyeK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# random.seed(42)\n",
        "\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "# View the first sample shape\n",
        "test_samples[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEqUukfTAyeK"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[test_labels[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0QDvOfZAyeK"
      },
      "outputs": [],
      "source": [
        "# Make predictions - randomly pick data from the test sets and predict on them to see what the model is doing\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                              data=test_samples)\n",
        "\n",
        "# View the first two predicition probabilities\n",
        "pred_probs[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMl51OWoAyeK"
      },
      "outputs": [],
      "source": [
        "# Convert pred probs to labels\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "ie_hpLrNM9kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9, 9))\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # Create subplot\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
        "\n",
        "  # Find the prediction label (in text form)\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # Get the truth label (in text form)\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # Create a title for the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality between pred and truth and change color of title text\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c=\"g\")  ## green test if prediction same as truth\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c=\"r\")  ## red test if prediction is not same as truth\n",
        "\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "c9nufZyZM9h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Making a confustion matrix for further prediction evaluation\n",
        "\n",
        "1. Make predicitons with out trained model on the test dataset\n",
        "2. make a confusion matrix - `torchmetrics.ConfusionMatrix`\n",
        "3. Plot the confusion matrix using `mlxtend.plotting.plot_confusion_matrix()`"
      ],
      "metadata": {
        "id": "im0jGRDxM9fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm.auto\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Make predictions with trained model\n",
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions...\"):\n",
        "    # Send the data to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    y_logit = model_2(X)\n",
        "\n",
        "    # Turn predictions from logits to predicition probs to pred labels\n",
        "    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
        "\n",
        "    # Put predictions on CPU for evaluation\n",
        "    y_preds.append(y_pred.cpu())\n",
        "\n",
        "  # Concatinate list of predictions into a tensor\n",
        "  # print(y_preds)\n",
        "  y_pred_tensor = torch.cat(y_preds)\n",
        "\n"
      ],
      "metadata": {
        "id": "okjxoS8t0qw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  y_pred_tensor"
      ],
      "metadata": {
        "id": "MGK1vzQZ3P71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_pred_tensor)"
      ],
      "metadata": {
        "id": "AwXpCS4d_9rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See if required packages are installed and if not, install them...\n",
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "  assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend version should be 0.19.0 or higher\"\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics, mlxtend\n",
        "  print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "M8pgw87GAQVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# 2. setup confusion instance and comparing predictions to targets\n",
        "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n",
        "confmat_tensor = confmat(preds=y_pred_tensor,\n",
        "                         target=test_data.targets)\n",
        "\n",
        "# 3. PLot the confustion matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(), ## matplotlib likes working with numpy\n",
        "                                class_names=class_names,\n",
        "                                figsize=(10, 7)\n",
        "                                )"
      ],
      "metadata": {
        "id": "AT1XT_v6BcbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Save and load best performing model"
      ],
      "metadata": {
        "id": "Y7Kv8bjZBcT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Create a model directory path\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "# Create a model save path\n",
        "MODEL_NAME = \"03_pytorch_computervision_model_2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save the models state_dict\n",
        "print(f\"Saving the model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "ZCR7XKKCBcRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new instance of model_2\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
        "                                     hidden_units=10,\n",
        "                                     output_shape=len(class_names))\n",
        "\n",
        "# Load in the saved state_dict\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Send the model to the target device\n",
        "loaded_model_2.to(device)"
      ],
      "metadata": {
        "id": "9DaCjC3SY6Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "gbc5kI89a9PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the loaded model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(model=loaded_model_2,\n",
        "                                    data_loader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    accuracy_fn=accuracy_fn)\n",
        "\n",
        "loaded_model_2_results"
      ],
      "metadata": {
        "id": "ELA0YtVpY6Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if results are close to eachother\n",
        "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "              torch.tensor(loaded_model_2_results[\"model_loss\"]))"
      ],
      "metadata": {
        "id": "1Pz3DNorY6PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TbYX2rogY6NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ekU8PoFY6LN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}